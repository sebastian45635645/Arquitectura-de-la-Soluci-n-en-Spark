Se realizó una corrección del código original (CONSUMER) debido a los siguientes aspectos: diferencias en el formato (las cuales generaban errores por el uso incorrecto de “/” y paréntesis), duplicidad en la creación de la SparkSession, y la limpieza general del código para mejorar su estructura y evitar fallos en la ejecución.


1.  (Codigo Original - Productor (producer) de Kafka)

import time
import json
import random
from kafka import KafkaProducer

def generate_sensor_data():
    return {
        "sensor_id": random.randint(1, 10),
        "temperature": round(random.uniform(20, 30), 2),
        "humidity": round(random.uniform(30, 70), 2),
        "timestamp": int(time.time())
    }

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8')
)

while True:
    sensor_data = generate_sensor_data()
    producer.send('sensor_data', value=sensor_data)
    print(f"Sent: {sensor_data}")
    time.sleep(1)


2.  (Codigo Funcional - Consumidor (Consumer) con Spark Streaming) 

from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, window
from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, TimestampType

# Crear la sesión de Spark
spark = SparkSession.builder.appName("KafkaSparkStreaming").getOrCreate()
spark.sparkContext.setLogLevel("WARN")

# Definir el esquema de los datos
schema = StructType([
    StructField("sensor_id", IntegerType()),
    StructField("temperature", FloatType()),
    StructField("humidity", FloatType()),
    StructField("timestamp", TimestampType())
])

# Leer desde Kafka
df = (
    spark.readStream
         .format("kafka")
         .option("kafka.bootstrap.servers", "localhost:9092")
         .option("subscribe", "sensor_data")
         .load()
)

# Parsear los datos JSON
parsed_df = (
    df.select(from_json(col("value").cast("string"), schema).alias("data"))
      .select("data.*")
)

# Calcular estadísticas por ventana
windowed_stats = (
    parsed_df.groupBy(window(col("timestamp"), "1 minute"), "sensor_id")
             .agg({"temperature": "avg", "humidity": "avg"})
)

# Escribir los resultados en consola
query = (
    windowed_stats.writeStream
                  .outputMode("complete")
                  .format("console")
                  .start()
)

query.awaitTermination()



